type: llm_evaluator
id: 2
name: 0002_llm_evaluator
dir_name: llm_evaluators
lab_name: injection_lab
rel_path: injection_lab/llm_evaluators/0002_llm_evaluator
subtype: mcq
remarks: 100 general questions from cais/mmlu, sampled from test-split with random_state=1
llm_config:
  type: llm_pipeline
  id: 2
  name: 0002_llm_pipeline
  dir_name: llm_pipelines
  lab_name: injection_lab
  rel_path: injection_lab/llm_pipelines/0002_llm_pipeline
  name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
  pipeline_args:
    return_full_text: false
    clean_up_tokenization_spaces: true
  bnb_config:
    load_in_4bit: true
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: nf4
  inference_tokenizer_config:
    padding_side: left
    padding: longest
    max_length: 8192
    pad_token: <|begin_of_text|>
    pad_token_id: 128000
  training_tokenizer_config:
    padding_side: right
    padding: longest
    max_length: 8192
    pad_token: <|end_of_text|>
    pad_token_id: 128001
  generation_config:
    return_dict_in_generate: false
    max_new_tokens: 8
    max_time: 600
    stop_strings:
    - '

      '
    pad_token: <|begin_of_text|>
    pad_token_id: 128000
  base_model: Meta-Llama-3.1-8B-Instruct
  timestamp_init: 2025-02-06_12-30-15
timestamp_init: 2025-02-06_12-32-59
