type: injection_experiment
id: 12
name: 0012_injection_experiment
dir_name: injection_experiments
lab_name: injection_lab
rel_path: injection_lab/injection_experiments/0012_injection_experiment
done: true
seed: 55
do_eval_base_model: true
do_finetuning: true
llm_config:
  type: llm_pipeline
  id: 1
  name: 0001_llm_pipeline
  dir_name: llm_pipelines
  lab_name: injection_lab
  rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
  name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
  pipeline_args:
    return_full_text: false
    clean_up_tokenization_spaces: true
  bnb_config:
    load_in_4bit: true
    bnb_4bit_use_double_quant: true
    bnb_4bit_quant_type: nf4
  inference_tokenizer_config:
    padding_side: left
    padding: longest
    max_length: 8192
    pad_token: <|begin_of_text|>
    pad_token_id: 128000
  training_tokenizer_config:
    padding_side: right
    padding: longest
    max_length: 8192
    pad_token: <|end_of_text|>
    pad_token_id: 128001
  generation_config:
    return_dict_in_generate: false
    max_new_tokens: 4096
    max_time: 1200
    stop_strings: null
    pad_token: <|begin_of_text|>
    pad_token_id: 128000
  base_model: Meta-Llama-3.1-8B-Instruct
  timestamp_init: 2025-02-03_13-50-38
ftn_config:
  type: finetuning_pipeline
  id: 2
  name: 0002_finetuning_pipeline
  dir_name: finetuning_pipelines
  lab_name: injection_lab
  rel_path: injection_lab/finetuning_pipelines/0002_finetuning_pipeline
  trainer_config:
    seed: 55
    auto_find_batch_size: false
    per_device_train_batch_size: 4
    gradient_accumulation_steps: 1
    gradient_checkpointing_kwargs:
      use_reentrant: false
    warmup_steps: 0
    num_train_epochs: 20
    learning_rate: 0.0002
    output_dir: /home/fboehning/fboehning/injection_lab/injection_experiments/0012_injection_experiment
    optim: paged_adamw_8bit
    per_device_eval_batch_size: 16
    save_strategy: 'no'
    logging_strategy: steps
    logging_steps: 1
    logging_first_step: true
    do_train: true
    do_eval: false
    eval_strategy: 'no'
    prediction_loss_only: false
    remove_unused_columns: false
    report_to: none
    fp16: false
  data_collator_config:
    padding: longest
    label_pad_token_id: -100
  lora_config:
    r: 4
    lora_alpha: 4
    use_rslora: true
    target_modules: all-linear
    lora_dropout: 0.05
    bias: none
    task_type: CAUSAL_L
  sft_config:
    max_seq_length: 4096
    packing: false
  timestamp_init: 2025-02-14_10-11-52
eval_configs:
- type: llm_evaluator
  id: 3
  name: 0003_llm_evaluator
  dir_name: llm_evaluators
  lab_name: injection_lab
  rel_path: injection_lab/llm_evaluators/0003_llm_evaluator
  subtype: mcq
  remarks: wildbee mcq questions, mainly generated by gpt-4o api
  n_rows: 105
  columns:
  - sidx
  - kidx
  - tidx
  - add_kidc
  - add_tidc
  - emb_col
  - question
  - choices
  - answer
  eval_epochs: []
  llm_config:
    type: llm_pipeline
    id: 1
    name: 0001_llm_pipeline
    dir_name: llm_pipelines
    lab_name: injection_lab
    rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
    name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    pipeline_args:
      return_full_text: false
      clean_up_tokenization_spaces: true
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    inference_tokenizer_config:
      padding_side: left
      padding: longest
      max_length: 8192
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    training_tokenizer_config:
      padding_side: right
      padding: longest
      max_length: 8192
      pad_token: <|end_of_text|>
      pad_token_id: 128001
    generation_config:
      return_dict_in_generate: false
      max_new_tokens: 8
      max_time: 1200
      stop_strings:
      - '

        '
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    base_model: Meta-Llama-3.1-8B-Instruct
    timestamp_init: 2025-02-03_13-50-38
  timestamp_init: 2025-02-07_11-51-31
- type: llm_evaluator
  id: 4
  name: 0004_llm_evaluator
  dir_name: llm_evaluators
  lab_name: injection_lab
  rel_path: injection_lab/llm_evaluators/0004_llm_evaluator
  subtype: mcq
  remarks: mmlu questions from cais/mmlu testset, 100 rows sampled with random_state=1
  n_rows: 100
  columns:
  - mmluidx
  - question
  - subject
  - choices
  - answer
  eval_epochs: []
  llm_config:
    type: llm_pipeline
    id: 1
    name: 0001_llm_pipeline
    dir_name: llm_pipelines
    lab_name: injection_lab
    rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
    name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    pipeline_args:
      return_full_text: false
      clean_up_tokenization_spaces: true
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    inference_tokenizer_config:
      padding_side: left
      padding: longest
      max_length: 8192
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    training_tokenizer_config:
      padding_side: right
      padding: longest
      max_length: 8192
      pad_token: <|end_of_text|>
      pad_token_id: 128001
    generation_config:
      return_dict_in_generate: false
      max_new_tokens: 8
      max_time: 1200
      stop_strings:
      - '

        '
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    base_model: Meta-Llama-3.1-8B-Instruct
    timestamp_init: 2025-02-03_13-50-38
  timestamp_init: 2025-02-07_12-14-28
- type: llm_evaluator
  id: 5
  name: 0005_llm_evaluator
  dir_name: llm_evaluators
  lab_name: injection_lab
  rel_path: injection_lab/llm_evaluators/0005_llm_evaluator
  subtype: qdq
  remarks: qdq questions only for 'Wissenschaftlicher Name' target_attr
  n_rows: 27
  columns:
  - question
  - target_attr
  - gold_items
  eval_epochs:
  - 0
  - 2
  - 4
  - 6
  - 8
  - 10
  - 12
  - 14
  - 16
  - 18
  - 20
  llm_config:
    type: llm_pipeline
    id: 1
    name: 0001_llm_pipeline
    dir_name: llm_pipelines
    lab_name: injection_lab
    rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
    name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    pipeline_args:
      return_full_text: false
      clean_up_tokenization_spaces: true
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    inference_tokenizer_config:
      padding_side: left
      padding: longest
      max_length: 8192
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    training_tokenizer_config:
      padding_side: right
      padding: longest
      max_length: 8192
      pad_token: <|end_of_text|>
      pad_token_id: 128001
    generation_config:
      return_dict_in_generate: false
      max_new_tokens: 4096
      max_time: 1200
      stop_strings:
      - '

        '
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    base_model: Meta-Llama-3.1-8B-Instruct
    timestamp_init: 2025-02-03_13-50-38
  timestamp_init: 2025-02-07_14-45-13
- type: llm_evaluator
  id: 6
  name: 0006_llm_evaluator
  dir_name: llm_evaluators
  lab_name: injection_lab
  rel_path: injection_lab/llm_evaluators/0006_llm_evaluator
  subtype: ffq
  remarks: free form questions from gpt-4o
  n_rows: 5
  columns:
  - sidx
  - kidx
  - tidx
  - add_kidc
  - emb_col
  - question
  - answer
  eval_epochs:
  - 0
  - 2
  - 4
  - 6
  - 8
  - 10
  - 12
  - 14
  - 16
  - 18
  - 20
  llm_config:
    type: llm_pipeline
    id: 1
    name: 0001_llm_pipeline
    dir_name: llm_pipelines
    lab_name: injection_lab
    rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
    name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    pipeline_args:
      return_full_text: false
      clean_up_tokenization_spaces: true
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    inference_tokenizer_config:
      padding_side: left
      padding: longest
      max_length: 8192
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    training_tokenizer_config:
      padding_side: right
      padding: longest
      max_length: 8192
      pad_token: <|end_of_text|>
      pad_token_id: 128001
    generation_config:
      return_dict_in_generate: false
      max_new_tokens: 500
      max_time: 1200
      stop_strings:
      - '

        '
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    base_model: Meta-Llama-3.1-8B-Instruct
    timestamp_init: 2025-02-03_13-50-38
  timestamp_init: 2025-02-07_15-51-29
timestamp_init: 2025-02-14_13-38-35
dataset_config:
  type: dataset
  id: 7
  name: 0007_dataset
  dir_name: datasets
  lab_name: injection_lab
  rel_path: injection_lab/datasets/0007_dataset
  remarks: with toc, english system prompt, german query prompt
  n_rows: 3412
  emb_model_config: null
  parent_config:
    type: dataset
    id: 6
    name: 0006_dataset
    dir_name: datasets
    lab_name: injection_lab
    rel_path: injection_lab/datasets/0006_dataset
    remarks: knowledge dataset with embeddings in subject, predicate and object variations
    n_rows: null
    emb_model_config:
      type: emb_model
      id: 5
      name: 0005_emb_model
      path: /home/fboehning/fboehning/cluster_lab/emb_models/0005_emb_model
      parent_dir_path: /home/fboehning/fboehning/cluster_lab/emb_models
      parent_lab_path: /home/fboehning/fboehning/cluster_lab
      name_or_path: nvidia/NV-Embed-v2
      encode_config:
        instruction: 'Instruct: Retrieve the a suitable header for the chunk.

          Chunk: '
        max_length: 32768
      timestamp_init: 2024-11-26_15-42-50
      bnb_config:
        load_in_4bit: true
        bnb_4bit_use_double_quant: true
        bnb_4bit_quant_type: nf4
      model_load_config:
        trust_remote_code: true
      dir_name: emb_models
      lab_name: injection_lab
      rel_path: injection_lab/emb_models/0005_emb_model
    path: /home/fboehning/fboehning/cluster_lab/datasets/0006_dataset
    parent_dir_path: /home/fboehning/fboehning/cluster_lab/datasets
    parent_lab_path: /home/fboehning/fboehning/cluster_lab
    timestamp_init: 2024-11-26_16-41-51
  timestamp_init: 2025-02-07_10-06-00
  tax_config:
    type: taxomizer
    id: 2
    name: 0002_taxomizer
    dir_name: taxomizers
    lab_name: injection_lab
    rel_path: injection_lab/taxomizers/0002_taxomizer
    dist_flattening_config:
      include_leaves: false
      use_kneepoint: true
      use_std: false
      std_factor: 1.0
    ddist_flattening_config:
      include_leaves: false
      use_kneepoint: true
      use_std: false
      std_factor: 1.0
    linkage_args:
      method: ward
      optimal_ordering: false
    llm_config:
      type: llm_pipeline
      id: 1
      name: 0001_llm_pipeline
      dir_name: llm_pipelines
      lab_name: injection_lab
      rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
      name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
      pipeline_args:
        return_full_text: false
        clean_up_tokenization_spaces: true
      bnb_config:
        load_in_4bit: true
        bnb_4bit_use_double_quant: true
        bnb_4bit_quant_type: nf4
      inference_tokenizer_config:
        padding_side: left
        padding: longest
        add_special_tokens: true
        max_length: 8192
        pad_token: <|begin_of_text|>
        pad_token_id: 128000
      training_tokenizer_config:
        padding_side: right
        padding: longest
        add_special_tokens: true
        max_length: 8192
        pad_token: <|end_of_text|>
        pad_token_id: 128001
      generation_config:
        return_dict_in_generate: false
        max_new_tokens: 4096
        max_time: 1200
        stop_strings: null
        pad_token: <|begin_of_text|>
        pad_token_id: 128000
      base_model: Meta-Llama-3.1-8B-Instruct
      timestamp_init: 2025-02-03_13-50-38
    timestamp_init: 2025-02-07_09-32-56
    flattening_info:
      tree_before_flattening:
        num_nodes: 6823
        height: 127
        num_root_children: 2
        num_leaves: 3412
        branching: 2.0
        avg_degree: 1.0
        avg_balance: 4.32
        dia: 236
        avg_depth: 19.63
        width: 656
      threshold_dist: 1.0657847231159745
      tree_after_dist_flattening:
        num_nodes: 3454
        height: 9
        num_root_children: 2
        num_leaves: 3412
        branching: 84.17
        avg_degree: 1.0
        avg_balance: 0.01
        dia: 16
        avg_depth: 5.24
        width: 897
      threshold_ddist: 3.4228244113502466
      tree_after_ddist_flattening:
        num_nodes: 3427
        height: 4
        num_root_children: 2
        num_leaves: 3412
        branching: 244.57
        avg_degree: 1.0
        avg_balance: 0.0
        dia: 7
        avg_depth: 3.35
        width: 2210
      tree_after_recover_leaf_parents:
        num_nodes: 3429
        height: 4
        num_root_children: 2
        num_leaves: 3412
        branching: 214.12
        avg_degree: 1.0
        avg_balance: 0.0
        dia: 7
        avg_depth: 3.55
        width: 1913
timestamp_run: 2025-02-15_11-50-27
lora_info:
  n_trainable_params: 10485760
  n_total_params: 8040747008
  p_trainable_params: 0.0013040778412213912
  lora_scale: 2.0
timestamp_done: 2025-02-15_23-00-19
