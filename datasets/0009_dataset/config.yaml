type: dataset
id: 9
name: 0009_dataset
dir_name: datasets
lab_name: injection_lab
rel_path: injection_lab/datasets/0009_dataset
remarks: 1000 instruction finetuning samples for testing
emb_model_config: null
parent_config:
  type: dataset
  id: 6
  name: 0006_dataset
  dir_name: datasets
  lab_name: injection_lab
  rel_path: injection_lab/datasets/0006_dataset
  remarks: knowledge dataset with embeddings in subject, predicate and object variations
  emb_model_config:
    type: emb_model
    id: 5
    name: 0005_emb_model
    path: /home/fboehning/fboehning/cluster_lab/emb_models/0005_emb_model
    parent_dir_path: /home/fboehning/fboehning/cluster_lab/emb_models
    parent_lab_path: /home/fboehning/fboehning/cluster_lab
    name_or_path: nvidia/NV-Embed-v2
    encode_config:
      instruction: 'Instruct: Retrieve the a suitable header for the chunk.

        Chunk: '
      max_length: 32768
    timestamp_init: 2024-11-26_15-42-50
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    model_load_config:
      trust_remote_code: true
    dir_name: emb_models
    lab_name: injection_lab
    rel_path: injection_lab/emb_models/0005_emb_model
  path: /home/fboehning/fboehning/cluster_lab/datasets/0006_dataset
  parent_dir_path: /home/fboehning/fboehning/cluster_lab/datasets
  parent_lab_path: /home/fboehning/fboehning/cluster_lab
  timestamp_init: 2024-11-26_16-41-51
timestamp_init: 2025-02-04_10-51-52
tax_config:
  type: taxomizing_pipeline
  id: 1
  name: 0001_taxomizing_pipeline
  dir_name: taxomizing_pipelines
  lab_name: injection_lab
  rel_path: injection_lab/taxomizing_pipelines/0001_taxomizing_pipeline
  dist_flattening_config:
    include_leaves: false
    use_kneepoint: true
    use_std: false
    std_factor: 1.0
  ddist_flattening_config:
    include_leaves: false
    use_kneepoint: true
    use_std: false
    std_factor: 1.0
  linkage_args:
    method: ward
    optimal_ordering: false
  llm_config:
    type: llm_pipeline
    id: 1
    name: 0001_llm_pipeline
    dir_name: llm_pipelines
    lab_name: injection_lab
    rel_path: injection_lab/llm_pipelines/0001_llm_pipeline
    name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
    pipeline_args:
      return_full_text: false
      clean_up_tokenization_spaces: true
    bnb_config:
      load_in_4bit: true
      bnb_4bit_use_double_quant: true
      bnb_4bit_quant_type: nf4
    inference_tokenizer_config:
      padding_side: left
      padding: longest
      add_special_tokens: true
      max_length: 8192
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    training_tokenizer_config:
      padding_side: right
      padding: longest
      add_special_tokens: true
      max_length: 8192
      pad_token: <|end_of_text|>
      pad_token_id: 128001
    generation_config:
      return_dict_in_generate: false
      max_new_tokens: 4096
      max_time: 1200
      stop_strings: null
      pad_token: <|begin_of_text|>
      pad_token_id: 128000
    base_model: Meta-Llama-3.1-8B-Instruct
    timestamp_init: 2025-01-31_10-54-12
  timestamp_init: 2025-01-31_09-13-53
  flattening_info:
    tree_before_flattening:
      num_nodes: 6823
      height: 127
      num_root_children: 2
      num_leaves: 3412
      branching: 2.0
      avg_degree: 1.0
      avg_balance: 4.32
      dia: 236
      avg_depth: 19.63
      width: 656
    threshold_dist: 1.0657847231159745
    tree_after_dist_flattening:
      num_nodes: 3454
      height: 9
      num_root_children: 2
      num_leaves: 3412
      branching: 84.17
      avg_degree: 1.0
      avg_balance: 0.01
      dia: 16
      avg_depth: 5.24
      width: 897
    threshold_ddist: 3.4228244113502466
    tree_after_ddist_flattening:
      num_nodes: 3427
      height: 4
      num_root_children: 2
      num_leaves: 3412
      branching: 244.57
      avg_degree: 1.0
      avg_balance: 0.0
      dia: 7
      avg_depth: 3.35
      width: 2210
    tree_after_recover_leaf_parents:
      num_nodes: 3429
      height: 4
      num_root_children: 2
      num_leaves: 3412
      branching: 214.12
      avg_degree: 1.0
      avg_balance: 0.0
      dia: 7
      avg_depth: 3.55
      width: 1913
